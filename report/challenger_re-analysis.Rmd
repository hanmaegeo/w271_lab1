---
title: "W271 Group Lab 1"
subtitle: "Investigating the 1986 Space Shuttle Challenger Accident"
author: "Nathan Martinez, Meera Sharma, Hannah George, and Haile Bizunehe"
fontsize: 11pt
geometry: margin=1in
documentclass: exam
classoption: answers
output: 
  pdf_document: 
    toc: true
    number_sections: true
---

\newpage

```{r load packages, message=FALSE, warning=FALSE, echo=FALSE}
list.of.packages <- c("tidyverse", "sandwich", "lmtest", "car", "MASS", "nnet", "cowplot")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(tidyverse)
library(sandwich)
library(lmtest)
library(car)
library(MASS)
library(nnet)
library(cowplot)
```

\newpage

```{=tex}
\begin{abstract} 
This report will, indeed, be abstract. No, instead, describe your goals your approach, and what you learn.
\end{abstract}
```

# Introduction

## Research question

\hrulefill

Our research question is:

*How does the expected number of O-ring failures change with varying temperature and pressure?*

# Data (20 points)

\hrulefill
```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```
```{r, warning=FALSE, message=FALSE, echo=FALSE}
df <- read_csv('../data/raw/challenger.csv')
```

```{r, warning=FALSE}
summary(df)
```

```{r, echo=FALSE, warning=FALSE}
df %>% 
  group_by(Temp, O.ring) %>%
  summarize(Count = n()) %>%
  ggplot(aes(x = Temp, y = O.ring, size = Count)) + 
    geom_point() + 
    labs(title = "Number of O-Ring Failures by Temperature") +
    theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
    ylab("Number of O-Ring Failures") +
    xlab("Temperature") -> p1

df %>% 
  group_by(Pressure, O.ring) %>%
  summarize(Count = n()) %>%
  ggplot(aes(x = Pressure, y = O.ring, size = Count)) + 
    geom_point() + 
    labs(title = "Number of O-Ring Failures by Pressure") +
    theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
    ylab("Number of O-Ring Failures") +
    xlab("Pressure") -> p2

ggplot(df, aes(x = O.ring, y = Temp, group = O.ring)) + 
  geom_boxplot() +
  labs(title = "Boxplot of O-Ring Failures by Temperature") +
  theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
  geom_jitter(width = 0.25) +
  ylab("Temperature") +
  xlab("Number of O-Ring Failures") -> p3

ggplot(df, aes(x = O.ring, y = Pressure, group = O.ring)) + 
  geom_boxplot() +
  labs(title = "Boxplot of O-Ring Failures by Pressure") +
  theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
  geom_jitter(width = 0.25) +
  ylab("Pressure") +
  xlab("Number of O-Ring Failures") -> p4

plot_grid(p1, p2, p3, p4)
```

Based on the scatter plots above, we can see there is a negative relationship between temperature and the number of O-ring failures, that is, as temperature increases the number of O-ring failures appears to decrease. This intuition is confirmed when we look at the box plot, with both the mean and quantiles for temperature decreasing as number of O-ring failures increases.

However, there does not appear to be much of a relationship at all when we look at pressure. The scatter plot appears randomly distributed and the box plot is non descriptive at best.

$$\\[0.1in]$$

## Description

\hrulefill

The data in this analysis is used from 23 out of 24 space shuttle orbital flights between April 12, 1981, and January 12, 1986, which covers all flights except one before the Space Shuttle Challenger disaster on January 28, 1986.  After each launch, the rocket motors were recovered from the ocean for inspection and potential reuse.  One flight data is missing as the booster sets were lost in the ocean and it was not possible to retrieve the data and inspect it. 

The data consists of temperature for the joints connecting the Solid Rocket Motor casings, propellant gas pressure, number of distressed thermal O-rings used to seal the joints, and the total number of O-rings. Our dependent variable is the number of distressed thermal O-rings used to seal the joints.

Our population is all O-rings used for space shuttle orbital flights before January 28, 1986 that use the improved version of Solid Rocket Motor Casing Joint Design that accommodates larger-sized shuttle rocket motors and has a second O-ring. The whole population is used in this analysis report.  It is important to note that joint temperatures were between 53°F and 81°F for the 23 space shuttle orbital flights, while the temperature on January 28, 1986 was 31°F.   

$$\\[0.1in]$$

\hrulefill

By taking independent assumptions for all flights, we can treat the number of distressed thermal O-rings as a binomial random variable and satisfy one of the requirements of a binomial regression that we will use for modeling.

The potential problem with the independence assumption is that if any O-ring is experiencing thermal distress, there is a high chance that other O-rings in the same space shuttle have similar distress. Second, there may be design changes on any of the four-vehicle fleets or how the flight is performed based on previous flight performance. If any of these changes happen, a relation between flights exists, and the previous flight affects the subsequent flight. An existence of dependency between the outcome can lead to substantial bias in estimated standard errors.

$$\\[0.1in]$$

## Key Features

\hrulefill

Figure TODO shows us that the majority of thermal distress on the O-Ring happened at temperatures 63 and below degrees Fahrenheit. Three thermal distress exceptions happened at 70 and 75 degrees Fahrenheit. Pressure wise, most failures happen at the high pressure with an exception on pressure 50.

For the figure TODO density plot, we first converted the 23 flight records to 138 records which cover one record for each O-ring. The density shows us that most of the failures happen at low temperatures. When it comes to pressure, there is less failure on low pressure, but there is equivalent failure and success on higher pressure.

Figure TODO shows that in general the failure rate of O-ring is low. In the joint distribution of temperature and pressure marked by the number of thermal distress on the O-Ring. Most of the distress happened at a pressure of 200 and temperatures 63 and below degrees Fahrenheit. The pressure does not give any additional clue on if it has a role in thermal distress as the joint distribution did not expand what we already learned from figure 1.

$$\\[0.1in]$$

# Analysis

## Reproducing Previous Analysis (10 points)

\hrulefill

Based on the original paper, the model they used appears to be a binomial logistic regression model, however, our outcome variable is outside the allowed range of (0, 1). Consequentially, we will need to divide the outcome variable by 6 in order to ensure it stays within the allowed range.

```{r}
model_1 <- glm(formula = O.ring / Number ~ Temp + Pressure, data = df,
               family = 'binomial', weights = Number)

Anova(model_1, test = 'LR')
```

Based on the results of the likelihood ratio test, and the EDA performed above, the pressure variable does not appear to have either a statistically significant or practically significant effect on the number of O-ring failures. However, temperature does appear to be significant and should be used in whichever model we create.

$$\\[0.1in]$$

\hrulefill

Based on the results of the likelihood ratio test above, we would also conclude that the pressure variable should not be included in the model. The effect of the variable is not statistically significant, and the scatter plot of pressure versus number of O-ring failures shows no correlation between the two.

$$\\[0.1in]$$

## Confidence Intervals (20 points)

\hrulefill

```{r}
# 1. Estimate the logistic regression model.
model_2 <- glm(formula = O.ring / Number ~ Temp, data = df, family = 'binomial',
               weights = Number)
summary(model_2)
```

```{r}
# 2. Determine if a quadratic term is needed in the model for the temperature in
#    this model.
model_3 <- glm(formula = O.ring / Number ~ Temp + I(Temp ^ 2), data = df,
               family = 'binomial', weights = Number)

Anova(model_3)
```

After looking at the likelihood ratio tests for a quadratic term, we would conclude that it is not necessary to include in the model. For the following purposes, we will use model 2.

```{r, echo=FALSE}
# Pi vs Temp plot.
res <- data.frame(Temp = 31:81)
prob_pred <- predict(model_2, res, type="response", se = TRUE)
res['pi_hat'] <- prob_pred$fit
linear_pred <- predict(model_2, res, type="link", se = TRUE)
lower <- linear_pred$fit - qnorm(1 - 0.05 / 2) * linear_pred$se.fit
upper <- linear_pred$fit + qnorm(1 - 0.05 / 2) * linear_pred$se.fit
res['lower'] <- exp(lower)/(1 + exp(lower))
res['upper'] <- exp(upper)/(1 + exp(upper))

ggplot(res, aes(x = Temp, y = pi_hat)) + 
  geom_line() +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + 
  labs(title = "Predicted Probability of O-Ring Failure vs Temperature") +
  theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
  ylab("Pi") +
  xlab("Temperature") -> p5

# Expected number of failures vs Temp plot.
res['pred_failures'] <- res$pi_hat * 6
res['failures_lower'] <- res$lower * 6
res['failures_upper'] <- res$upper * 6

ggplot(res, aes(x = Temp, y = pred_failures)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = failures_lower, ymax = failures_upper), alpha = 0.2) + 
  labs(title = "Predicted Number of O-Ring Failures vs Temperature") +
  theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
  ylab("O-Ring Failures") +
  xlab("Temperature") -> p6

plot_grid(p5, p6, nrows=2)
```
The confidence intervals get much larger as temperature decreases, this is because the training data did not have too many low-temperature examples. Leading the model to be more uncertain at lower temperatures.

$$\\[0.1in]$$

\hrulefill

When the temperature is 31°, the estimated probability of O-ring failure is `r round(res[res$Temp == 31,]['pi_hat'], 4)` (`r round(res[res$Temp == 31,]['lower'], 4)`, `r round(res[res$Temp == 31,]['upper'], 4)`). This confidence interval is fairly wide, but an O-ring failure does appear to be more likely than not. In order to believe this inference we have to have faith that the model is accurately making predictions for data that it doesn't have any examples of. The data the model trained on doesn't have any examples of a temperature this low so it's just speculating based on the trend from higher-temperature data. This speculation assumes a linear trend, which there just isn't a lot of data to back that assumption. So altogether we would be skeptical of the model's predictions.

$$\\[0.1in]$$

## Bootstrap Confidence Intervals (30 points)

\hrulefill

```{r bootstrap-confidence-intervals}
incidents.estimator <- function(b, seed=42, number=6) {
  # Setting seed to make the plot exactly reproduced
  set.seed(seed)
  n <- 23 # Resampled size
  estimation <- array(data = NA, dim=c(91, b))
  
  # Performing re-sampling repeatedly "b" times
  for(i in 1:b) {
    samples <- sample(x = 1:n, size = n, replace = TRUE)
    model   <- glm(formula = O.ring / Number ~ Temp, data = df[samples,],
                   weights = Number, family = 'binomial')
    # Performing prediction for 10-100° Fahrenheit using each fitted model 
    preds <- predict(object = model, newdata = data.frame(Temp = 10:100),
                     type = "response")
    j <- 0
    for(p in preds) {
      j <- j+1 # Index
      estimation[j, i] <- p
    }
  }
  # Fitting a model with the original data for prediction
  model <- glm(formula = O.ring/Number ~ Temp, data = df,
               weights = Number, family = 'binomial')
  # Estimating Expected number of incidents along with 90% CI
  incidents <- data.frame(Temperature = integer(), Incidents = double(),
                          CI.Upper = double(), CI.Lower = double())
  preds <- predict(object = model, newdata = data.frame(Temp = 10:100),
                   type = "response")
  i <- 0
  for(p in preds) {
    i <- i+1 # Index to locate data in the data.frame
    # Getting the 90% CI and multiply by 6 to get estimation for a single flight
    ci <- quantile(estimation[i,], probs = c(0.05, 0.95), names=FALSE)
    incidents[i, 1] <- i + 9 # Temperature
    incidents[i, 2] <- p*number
    incidents[i, 3] <- ci[1]*number
    incidents[i, 4] <- ci[2]*number
  }

  incidents
}

# Performing predictions for 10°-100° temperature and plotting the result
predicted.incidents <- incidents.estimator(1000)
```

```{r, echo=FALSE}
ggplot(predicted.incidents, aes(x=Temperature)) + 
  geom_line(aes(y = Incidents)) +
  geom_ribbon(aes(ymin = CI.Lower, ymax = CI.Upper), alpha = 0.2) + 
  labs(title = "Expected Number of Incidents by Temperature") +
  theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
  xlab("Temperature in degree fahrenheit") +
  ylab("Expected number of incidents") -> p7

plot_grid(NULL, p7, NULL, nrows=2, ncols=3)
```

## Alternative Specification (10 points)

```{r}
mod.linear <- lm(O.ring ~ Temp, data = df)
summary(mod.linear)
```

> 'The Temperature is statistically significant and negatively related to the number of O-ring failures for a given flight. For every 1-degree Fahrenheit increase, the number of O-ring failures decreases by 0.04754.'

```{r, echo=FALSE}
par(mfrow=c(2,2))
plot(mod.linear)
```

In the residuals vs fitted plot, there is some non-linear relationship that was not explained by the model and left out in the residuals. In the Q-Q plot, the residuals are supposed to follow a straight line to be normally distributed, but it deviates by forming a curve which might be a result of skewed data. In the scale-location plot, which shows us if there is equal variance (homoscedasticity), we see that the residuals are not randomly spread, and because of that, the smooth red line is not horizontal. In the Residual vs Leverage plot, which shows us that if there are influential observations. All the observations are within Cook's distance lines, with one observation 14 on the borderline. We can say that there are no influential cases that can alter the slope coefficient significantly if removed.  

Assessments for linear regression model assumptions:  
The first assumption is that the data is generated using the Independent and Identically Distributed (IID) sampling process to ensure that the data comes from the same process and that conclusions can be made from a sample to the full population. For this analysis, we used the entire population needed to asses the Challenger disaster on January 28, 1986, and it satisfies the identically distributed requirement. There is a potential for each flight to have a dependency, but there is no evidence that the flight operation and the design is changed based on previous flight performance; as a result, we can assume that they are independent. The second assumption is linearity (Linear Conditional Expectation), which is one of the three conditions we need to meet under CLM to make our OLS regression model produce unbiased estimates. In order to evaluate the linearity, we examined the model's residuals against the Temp explaining variable, and we can see that the linear relationship does not exist and the assumption is not satisfied. The third assumption is no perfect collinearity where there is no exact linear relationship among the independent variables. Our model has only one variable, and this assumption is satisfied. The fourth assumption is zero conditional mean error which is diagnosed using residuals vs fitted values in the above figure to evaluate if the error (residual) of the model is centered on prediction. In the plot, we see a non-linear relationship that needs to be modeled. As a result, the assumption is not satisfied. The fifth assumption is homoskedastic errors where we have constant error variance across the entire range of the x's. Using occular test, we can see that homoskedastic errors assumption is not satisfied. The sixth assumption is normally distributed errors which is not the case as shown on the Q-Q plot.  

The linear regression violated many assumptions, and its prediction can go negative or above 6, which is invalid. As a result, binary logistic regression is better than linear regression.

\hrulefill

# Conclusions (10 points)

Interpret the main result of your preferred model in terms of both odds and probability of failure. Summarize this result with respect to the question(s) being asked and key takeaways from the analysis.

\hrulefill

INSERT WRITEUP HERE.

