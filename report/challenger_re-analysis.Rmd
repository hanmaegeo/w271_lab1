---
title: "W271 Group Lab 1"
subtitle: "Investigating the 1986 Space Shuttle Challenger Accident"
author: "Nathan Martinez, Meera Sharma, Hannah George, and Haile Bizunehe"
fontsize: 11pt
geometry: margin=1in
documentclass: exam
classoption: answers
output: 
  pdf_document: 
    toc: true
    number_sections: true
---

\newpage

```{r load packages, message=FALSE, warning=FALSE, echo=FALSE}
list.of.packages <- c("tidyverse", "sandwich", "lmtest", "car", "MASS", "nnet", "cowplot")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(tidyverse)
library(sandwich)
library(lmtest)
library(car)
library(MASS)
library(nnet)
library(cowplot)
```

\newpage

```{=tex}
\begin{abstract} 
This report will, indeed, be abstract. No, instead, describe your goals your approach, and what you learn.
\end{abstract}
```

$$\\[0.1in]$$

# Introduction

## Research question

\hrulefill

Our research question is:

*How does the expected number of O-ring failures change with varying temperature and pressure?*


$$\\[0.1in]$$

# Data (20 points)

**Complete the following task. In your final submission, please remove this question prompt so that your report reads as a report. The Data Section of this report is worth 20 points.**

-   Conduct a thorough EDA of the data set.

    -   This should include both graphical and tabular analysis as taught in this course.
    -   Since the report has a page-limit, you will have to be selective when choosing visuals to illustrate your key points, associated with a concise explanation of the visuals.

-   This EDA should begin with an inspection of the given dataset; examination of anomalies, missing values, potential of top and/or bottom code etc.

\hrulefill

```{r, warning=FALSE, message=FALSE, echo=FALSE}
df <- read_csv('../data/raw/challenger.csv')
```

```{r, warning=FALSE}
summary(df)
```

```{r, echo=FALSE, warning=FALSE}
df %>% 
  group_by(Temp, O.ring) %>%
  summarize(Count = n()) %>%
  ggplot(aes(x = Temp, y = O.ring, size = Count)) + 
    geom_point() + 
    labs(title = "Number of O-Ring Failures by Temperature") +
    theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
    ylab("Number of O-Ring Failures") +
    xlab("Temperature") -> p1

df %>% 
  group_by(Pressure, O.ring) %>%
  summarize(Count = n()) %>%
  ggplot(aes(x = Pressure, y = O.ring, size = Count)) + 
    geom_point() + 
    labs(title = "Number of O-Ring Failures by Pressure") +
    theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
    ylab("Number of O-Ring Failures") +
    xlab("Pressure") -> p2

ggplot(df, aes(x = O.ring, y = Temp, group = O.ring)) + 
  geom_boxplot() +
  labs(title = "Boxplot of O-Ring Failures by Temperature") +
  theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
  ylab("Temperature") +
  xlab("Number of O-Ring Failures") -> p3

ggplot(df, aes(x = O.ring, y = Pressure, group = O.ring)) + 
  geom_boxplot() +
  labs(title = "Boxplot of O-Ring Failures by Pressure") +
  theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
  ylab("Pressure") +
  xlab("Number of O-Ring Failures") -> p4

plot_grid(p1, p2, p3, p4)
```

Based on the scatter plots above, we can see there is a negative relationship between temperature and the number of O-ring failures, that is, as temperature increases the number of O-ring failures appears to decrease. This intuition is confirmed when we look at the box plot, with both the mean and quantiles for temperature decreasing as number of O-ring failures increases.

However, there does not appear to be much of a relationship at all when we look at pressure. The scatter plot appears randomly distributed and the box plot is non descriptive at best.

$$\\[0.1in]$$

## Description

**Complete the following task. In your final submission, please remove this question prompt so that your report reads as a report.**

-   Describe the data that you are using. How is this data generated, what is the sampling process that brought it to your availability. If it is helpful, you might describe the population (i.e. the Random Variables) that exist and how samples are produced from these random variables.

\hrulefill

The data in this analysis is used from 23 out of 24 space shuttle orbital flights between April 12, 1981, and January 12, 1986, which covers all flights except one before the Space Shuttle Challenger disaster on January 28, 1986.  After each launch, the rocket motors were recovered from the ocean for inspection and potential reuse.  One flight data is missing as the booster sets were lost in the ocean and it was not possible to retrieve the data and inspect it. 

The data consists of temperature for the joints connecting the Solid Rocket Motor casings, propellant gas pressure, number of distressed thermal O-rings used to seal the joints, and the total number of O-rings. Our dependent variable is the number of distressed thermal O-rings used to seal the joints.

Our population is all O-rings used for space shuttle orbital flights before January 28, 1986 that use the improved version of Solid Rocket Motor Casing Joint Design that accommodates larger-sized shuttle rocket motors and has a second O-ring. The whole population is used in this analysis report.  It is important to note that joint temperatures were between 53°F and 81°F for the 23 space shuttle orbital flights, while the temperature on January 28, 1986 was 31°F.   

$$\\[0.1in]$$

-   The authors use logistic regression to estimate the probability an O-ring will fail. In order to use this model, the authors needed to assume that each O-ring is independent for each launch. Discuss why this assumption is necessary and the potential problems with it. Note that a subsequent analysis helped to alleviate the authors' concerns about independence.

\hrulefill

By taking independent assumptions for all flights, we can treat the number of distressed thermal O-rings as a binomial random variable and satisfy one of the requirements of a binomial regression that we will use for modeling.

The potential problem with the independence assumption is that if any O-ring is experiencing thermal distress, there is a high chance that other O-rings in the same space shuttle have similar distress. Second, there may be design changes on any of the four-vehicle fleets or how the flight is performed based on previous flight performance. If any of these changes happen, a relation between flights exists, and the previous flight affects the subsequent flight. An existence of dependency between the outcome can lead to substantial bias in estimated standard errors.

$$\\[0.1in]$$

## Key Features

\hrulefill

Figure TODO shows us that the majority of thermal distress on the O-Ring happened at temperatures 63 and below degrees Fahrenheit. Three thermal distress exceptions happened at 70 and 75 degrees Fahrenheit. Pressure wise, most failures happen at the high pressure with an exception on pressure 50.

For the figure TODO density plot, we first converted the 23 flight records to 138 records which cover one record for each O-ring. The density shows us that most of the failures happen at low temperatures. When it comes to pressure, there is less failure on low pressure, but there is equivalent failure and success on higher pressure.

Figure TODO shows that in general the failure rate of O-ring is low. In the joint distribution of temperature and pressure marked by the number of thermal distress on the O-Ring. Most of the distress happened at a pressure of 200 and temperatures 63 and below degrees Fahrenheit. The pressure does not give any additional clue on if it has a role in thermal distress as the joint distribution did not expand what we already learned from figure 1.

$$\\[0.1in]$$

# Analysis

## Reproducing Previous Analysis (10 points)

**Your analysis should address the following two questions. In your final submission, please remove this question prompt so that your report reads as a report.**

1.  Estimate the logistic regression model that the authors present in their report -- include the variables as linear terms in the model. Evaluate, using likelihood ratio tests, the statistical significance of each explanatory variable in the model. Evaluate, using the context and data understanding that you have created in the **Data** section of this report, the practical significance of each explanatory variable in the model.

\hrulefill

Based on the original paper, the model they used appears to be a binomial logistic regression model, however, our outcome variable is outside the allowed range of (0, 1). Consequentially, we will need to divide the outcome variable by 6 in order to ensure it stays within the allowed range.

```{r}
model_1 <- glm(formula = O.ring / 6 ~ Temp + Pressure, data = df,
               family = 'binomial', weights = Number)

Anova(model_1, test = 'LR')
```

Based on the results of the likelihood ratio test, and the EDA performed above, the pressure variable does not appear to have either a statistically significant or practically significant effect on the number of O-ring failures. However, temperature does appear to be significant and should be used in whichever model we create.

$$\\[0.1in]$$

2.  Dalal, Fowlkes, and Hoadley (1989) chose to remove `pressure` from the model based on their likelihood ratio tests. Critically evaluate, using your test results and understanding of the question and data, whether `pressure` should be included in the model, or instead, `pressure` should not be included in the model. Your report needs to make a determination, argue why it is most appropriate choice, and make note of how (if at all) the model results are affected by the choice of including or excluding `pressure`.

\hrulefill

Based on the results of the likelihood ratio test above, we would also conclude that the pressure variable should not be included in the model. The effect of the variable is not statistically significant, and the scatter plot of pressure versus number of O-ring failures shows no correlation between the two.

$$\\[0.1in]$$

## Confidence Intervals (20 points)

No matter what you determined about using or dropping `pressure`, for this section begin by considering the simplified model $logit(\pi) = \beta_0 + \beta_1 Temp$, where $\pi$ is the probability of an O-ring failure. Complete the following:

1.  Estimate the logistic regression model.
2.  Determine if a quadratic term is needed in the model for the temperature in this model.
3.  Construct two plots:
4.  $\pi$ vs. Temp; and,
5.  Expected number of failures vs. Temp.

Specific requirements for these plots:

-   Use a temperature range of 31° to 81° on the x-axis even though the minimum temperature in the data set was 53°.\
-   Include the 95% Wald confidence interval bands for $\pi$ on the plot. Describe, in your analysis of these plots, why the bands much wider for lower temperatures than for higher temperatures?

\hrulefill

```{r}
# 1. Estimate the logistic regression model.
model_2 <- glm(formula = O.ring / 6 ~ Temp, data = df, family = 'binomial',
               weights = Number)
summary(model_2)
```

```{r}
# 2. Determine if a quadratic term is needed in the model for the temperature in
#    this model.
model_3 <- glm(formula = O.ring / 6 ~ Temp + I(Temp ^ 2), data = df,
               family = 'binomial', weights = Number)

Anova(model_3)
```

After looking at the likelihood ratio tests for a quadratic term, we would conclude that it is not necessary to include in the model. For the following purposes, we will use model 2.

```{r, echo=FALSE}
# Pi vs Temp plot.
res <- data.frame(Temp = 31:81)
prob_pred <- predict(model_2, res, type="response", se = TRUE)
res['pi_hat'] <- prob_pred$fit
linear_pred <- predict(model_2, res, type="link", se = TRUE)
lower <- linear_pred$fit - qnorm(1 - 0.05 / 2) * linear_pred$se.fit
upper <- linear_pred$fit + qnorm(1 - 0.05 / 2) * linear_pred$se.fit
res['lower'] <- exp(lower)/(1 + exp(lower))
res['upper'] <- exp(upper)/(1 + exp(upper))

ggplot(res, aes(x = Temp, y = pi_hat)) + 
  geom_line() +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + 
  labs(title = "Predicted Probability of O-Ring Failure vs Temperature") +
  theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
  ylab("Pi") +
  xlab("Temperature") -> p5

# Expected number of failures vs Temp plot.
res['pred_failures'] <- res$pi_hat * 6
res['failures_lower'] <- res$lower * 6
res['failures_upper'] <- res$upper * 6

ggplot(res, aes(x = Temp, y = pred_failures)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = failures_lower, ymax = failures_upper), alpha = 0.2) + 
  labs(title = "Predicted Number of O-Ring Failures vs Temperature") +
  theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
  ylab("O-Ring Failures") +
  xlab("Temperature") -> p6

plot_grid(p5, p6, nrows=2)
```
The confidence intervals get much larger as temperature decreases, this is because the training data did not have too many low-temperature examples. Leading the model to be more uncertain at lower temperatures.

$$\\[0.1in]$$

3.  The temperature was 31° at launch for the Challenger in 1986. Estimate the probability of an O-ring failure using this temperature, and compute a corresponding confidence interval. Discuss what assumptions need to be made in order to apply the inference procedures.

\hrulefill

When the temperature is 31°, the estimated probability of O-ring failure is `r round(res[res$Temp == 31,]['pi_hat'], 4)` (`r round(res[res$Temp == 31,]['lower'], 4)`, `r round(res[res$Temp == 31,]['upper'], 4)`). This confidence interval is fairly wide, but an O-ring failure does appear to be more likely than not. In order to believe this inference we have to have faith that the model is accurately making predictions for data that it doesn't have any examples of. The data the model trained on doesn't have any examples of a temperature this low so it's just speculating based on the trend from higher-temperature data. This speculation assumes a linear trend, which there just isn't a lot of data to back that assumption. So altogether we would be skeptical of the model's predictions.

$$\\[0.1in]$$

## Bootstrap Confidence Intervals (30 points)

Rather than relying on asymptotic properties, consider using a parametric bootstrap, as did Dalal, Fowlkes and Hoadley. To do this:

1.  Simulate a large number of data sets (n = 23 for each) by re-sampling with replacement from the data.
2.  Estimate a model for each dataset.
3.  Compute the effect at a specific temperature of interest.

To produce a confidence interval, the authors used the 0.05 and 0.95 observed quantiles from the simulated distribution as their 90% confidence interval limits.

Using the parametric bootstrap, compute 90% confidence intervals separately at each integer temperature between 10° and 100° Fahrenheit.

In this section, you should describe your process, justify such a process, and present your results in a way that is compelling for your reader.

\hrulefill

```{r bootstrap-confidence-intervals}
incidents.estimator <- function(b, seed=42, number=6) {
  # Setting seed to make the plot exactly reproduced
  set.seed(seed)
  n <- 23 # Resampled size
  estimation <- array(data = NA, dim=c(91, b))
  
  # Performing re-sampling repeatedly "b" times
  for(i in 1:b) {
    samples <- sample(x = 1:n, size = n, replace = TRUE)
    model   <- glm(formula = O.ring / Number ~ Temp, data = df[samples,],
                   weights = Number, family = 'binomial')
    # Performing prediction for 10-100° Fahrenheit using each fitted model 
    for(t in 10:100) {
      p <- predict(object = model, newdata = data.frame(Temp = t),
                   type = "response")
      estimation[t-9, i] <- p
    }
  }

  # Fitting a model with the original data for prediction
  model <- glm(formula = O.ring/6 ~ Temp, data = df,
               weights = Number, family = 'binomial')
  # Estimating Expected number of incidents along with 90% CI
  incidents <- data.frame(Temperature = integer(),
                          Incidents = double(),
                          CI.Upper = double(),
                          CI.Lower = double())
  for(t in 10:100) {
    i <- t-9 # Index to locate data in the data.frame
    p <- predict(object = model, newdata = data.frame(Temp = t),
                 type = "response")
    # Getting the 90% CI and multiply by 6 to get estimation for a single flight
    ci <- quantile(estimation[i,], probs = c(0.05, 0.95), names=FALSE)
    incidents[i, 1] <- t
    incidents[i, 2] <- p*number
    incidents[i, 3] <- ci[1]*number
    incidents[i, 4] <- ci[2]*number
  }

  incidents
}
```

```{r, echo=FALSE, warning=FALSE}
# Performing predictions for 10°-100° temperature and plotting the result
predicted.incidents <- incidents.estimator(1000)

ggplot(predicted.incidents, aes(x=Temperature)) + 
  geom_line(aes(y = Incidents)) +
  geom_ribbon(aes(ymin = CI.Lower, ymax = CI.Upper), alpha = 0.2) + 
  labs(title = "Expected Number of Incidents by Temperature") +
  theme(plot.title = element_text(size = 10), text = element_text(size = 8)) +
  xlab("Temperature in degree fahrenheit") +
  ylab("Expected number of incidents") -> p7

plot_grid(NULL, p7, NULL, nrows=2, ncols=3)
```


$$\\[0.1in]$$

## Alternative Specification (10 points)

With the same set of explanatory variables in your final model, estimate a linear regression model. Explain the model results; conduct model diagnostic; and assess the validity of the model assumptions. Would you use the linear regression model or binary logistic regression in this case? Explain why.

\hrulefill

INSERT WRITEUP HERE.

$$\\[0.1in]$$

# Conclusions (10 points)

Interpret the main result of your preferred model in terms of both odds and probability of failure. Summarize this result with respect to the question(s) being asked and key takeaways from the analysis.

\hrulefill

INSERT WRITEUP HERE.

